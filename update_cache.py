#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
vacancy-dashboard äºˆç´„åœ¨åº« & æ–™é‡‘ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ¯æ—¥ GitHub Actions ã‹ã‚‰å‘¼ã°ã‚Œã¦
  â€¢ vacancy_price_cache.json        â€¦ ç›´è¿‘ 3 ã‹æœˆåˆ†ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿
  â€¢ vacancy_price_cache_previous.json â€¦ 1 æ—¥å‰ãƒ‡ãƒ¼ã‚¿ï¼ˆå·®åˆ†è¨ˆç®—ç”¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
  â€¢ historical_data.json            â€¦ æœªæ¥æ—¥ã”ã¨ã®å±¥æ­´ï¼ˆ3 ã‹æœˆåˆ†ã¾ã§ä¿æŒï¼‰
ã‚’æ›´æ–°ã—ã¾ã™ã€‚
"""

import os
import sys
import json
import calendar
import requests
import datetime as dt
from pathlib import Path
from dateutil.relativedelta import relativedelta

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å®šæ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
APP_ID          = os.environ.get("RAKUTEN_APP_ID", "")
if not APP_ID:
    raise ValueError("âŒ RAKUTEN_APP_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚GitHub Secrets ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã‹ï¼Ÿ")

CACHE_FILE      = "vacancy_price_cache.json"
PREV_CACHE_FILE = "vacancy_price_cache_previous.json"
HISTORICAL_FILE = "historical_data.json"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ¥½å¤©ãƒˆãƒ©ãƒ™ãƒ« API ã‹ã‚‰ 1 æ—¥åˆ†ã®åœ¨åº«æ•°ãƒ»å¹³å‡å˜ä¾¡ã‚’å–å¾—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_vacancy_and_price(target: dt.date) -> dict:
    print(f"ğŸ” fetching {target}", file=sys.stderr)
    prices: list[float] = []
    vacancy_total = 0

    url = "https://app.rakuten.co.jp/services/api/Travel/VacantHotelSearch/20170426"
    for page in range(1, 4):                                   # ä¸Šä½ 3 ãƒšãƒ¼ã‚¸ â‰’ 90 æ–½è¨­
        params = {
            "applicationId": APP_ID,
            "format": "json",
            "checkinDate":  target.strftime("%Y-%m-%d"),
            "checkoutDate": (target + dt.timedelta(days=1)).strftime("%Y-%m-%d"),
            "adultNum": 1,
            "largeClassCode":  "japan",
            "middleClassCode": "osaka",
            "smallClassCode":  "shi",
            "detailClassCode": "D",
            "page": page,
        }
        try:
            res = requests.get(url, params=params, timeout=10)
            res.raise_for_status()
            data = res.json()
        except Exception as e:
            print(f"  âš ï¸ fetch error on {target} page {page}: {e}", file=sys.stderr)
            continue

        # 1 ãƒšãƒ¼ã‚¸ç›®ã® recordCount ãŒæ®‹å®¤ï¼ˆæ–½è¨­ï¼‰æ•°
        if page == 1:
            vacancy_total = data.get("pagingInfo", {}).get("recordCount", 0)

        for hotel in data.get("hotels", []):
            parts = hotel.get("hotel", [])
            if len(parts) >= 2:
                for plan in parts[1].get("roomInfo", []):
                    total = plan.get("dailyCharge", {}).get("total")
                    if total is not None:
                        prices.append(total)

    avg_price = round(sum(prices) / len(prices), 0) if prices else 0.0
    print(f"   â†’ avg_price = {avg_price}  (vacancy={vacancy_total})", file=sys.stderr)
    return {"vacancy": vacancy_total, "avg_price": avg_price}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³æ›´æ–°å‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def update_cache(start_date: dt.date, months: int = 9) -> dict:
    """
    ãƒ»æœªæ¥æ—¥ï¼ˆstart_date ã‹ã‚‰ months ã‹æœˆåˆ†ï¼‰ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ cache ã‚’æ›´æ–°
    ãƒ»å‰æ—¥ã¨ã®å·®åˆ†ã‚’è¨ˆç®—ã—ã¦è¨˜éŒ²
    ãƒ»historic_data.json è¿½è¨˜ã‚‚ã“ã“ã§ã¯è¡Œã‚ãªã„ï¼ˆmain ç¯€ã§å®Ÿæ–½ï¼‰
    """
    today = dt.date.today()
    three_months_ago = today - relativedelta(months=3)

    # æ—¢å­˜ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    cache: dict[str, dict] = {}
    if Path(CACHE_FILE).exists():
        cache = json.loads(Path(CACHE_FILE).read_text(encoding="utf-8"))

    # å‰å›ï¼ˆå‰æ—¥ï¼‰å–å¾—ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    old_cache: dict[str, dict] = {}
    if Path(PREV_CACHE_FILE).exists():
        old_cache = json.loads(Path(PREV_CACHE_FILE).read_text(encoding="utf-8"))

    # 3 ã‹æœˆã‚ˆã‚Šå¤ã„ã‚­ãƒ¼ã‚’å‰Šé™¤
    cache = {
        k: v for k, v in cache.items()
        if dt.date.fromisoformat(k) >= three_months_ago
    }

    cal = calendar.Calendar(firstweekday=calendar.SUNDAY)

    # â”€â”€ ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ«ãƒ¼ãƒ— â”€â”€
    for m in range(months):
        base_month = (start_date + relativedelta(months=m)).replace(day=1)
        for week in cal.monthdatescalendar(base_month.year, base_month.month):
            for day in week:
                # å¯¾è±¡æœˆã‹ã¤ â€œä»Šæ—¥ä»¥é™â€ ã®æ—¥ä»˜ã®ã¿
                if day.month != base_month.month or day < today:
                    continue

                iso = day.isoformat()
                new = fetch_vacancy_and_price(day)
                if new["vacancy"] == 0 and new["avg_price"] == 0:
                    print(f"â© skip {iso} : empty result", file=sys.stderr)
                    continue

                new_vac, new_pri = new["vacancy"], new["avg_price"]
                prev = old_cache.get(iso, {})

                last_vac = prev.get("vacancy", new_vac)
                last_pri = prev.get("avg_price", new_pri)

                record = {
                    "vacancy":        new_vac,
                    "avg_price":      new_pri,
                    "last_vacancy":   last_vac,
                    "last_avg_price": last_pri,
                    "vacancy_diff":   new_vac - last_vac,
                    "avg_price_diff": new_pri - last_pri,
                }
                cache[iso] = record

    # ä¿å­˜
    Path(CACHE_FILE).write_text(
        json.dumps(cache, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    print("âœ… cache updated", file=sys.stderr)

    # â€œä»Šå›â€ ã‚’ next run ç”¨ previous ã¨ã—ã¦ä¿å­˜
    Path(PREV_CACHE_FILE).write_text(
        json.dumps(cache, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    return cache


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# historical_data.json ã®ä¿å®ˆ / è¿½è¨˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def update_history(cache: dict):
    today = dt.date.today()
    today_str = today.isoformat()

    hist: dict[str, dict] = {}
    if Path(HISTORICAL_FILE).exists():
        try:
            with open(HISTORICAL_FILE, "r", encoding="utf-8") as f:
                hist = json.load(f)
        except Exception as e:
            print(f"âš ï¸ error loading history: {e}", file=sys.stderr)

    # 1) ä»Šæ—¥ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å±¥æ­´ã«è¿½è¨˜
    for iso, v in cache.items():
        iso_date = dt.date.fromisoformat(iso)
        if iso_date >= today:
            hist.setdefault(iso, {})
            hist[iso][today_str] = {
                "vacancy":   v["vacancy"],
                "avg_price": v["avg_price"],
            }

    # 2) å„æ—¥ä»˜ã®å±¥æ­´ã‚’ã€Œãã®æ—¥ã‹ã‚‰ 3 ã‹æœˆè¶…ãˆãŸã‚‰å‰Šé™¤ã€
    for date_key in list(hist.keys()):
        date_dt = dt.date.fromisoformat(date_key)
        limit   = date_dt - relativedelta(months=3)
        for hist_key in list(hist[date_key].keys()):
            if dt.date.fromisoformat(hist_key) < limit:
                del hist[date_key][hist_key]
        if not hist[date_key]:      # ç©ºãªã‚‰å‰Šé™¤
            del hist[date_key]

    # ä¿å­˜
    Path(HISTORICAL_FILE).write_text(
        json.dumps(hist, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    print("ğŸ“ historical_data.json updated", file=sys.stderr)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸ“¡ Starting update_cache.py", file=sys.stderr)
    base = dt.date.today()
    new_cache = update_cache(base, months=9)
    update_history(new_cache)
