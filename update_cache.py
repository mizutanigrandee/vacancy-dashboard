#!/usr/bin/env python
"""
update_cache.py
â€“ æœªæ¥æ—¥ã®åœ¨åº«ãƒ»å¹³å‡æ–™é‡‘ã‚’å–å¾—ã—ã¦
  vacancy_price_cache.json / historical_data.json / demand_spike_history.json ã‚’æ›´æ–°
  ï¼‹ GitHub Actions å®Ÿè¡Œå®Œäº†ã®JSTæ™‚åˆ»ã‚’ last_updated.json ã«æ›¸ãå‡ºã™
"""

import os
import sys
import json
import calendar
import requests
import datetime as dt
from pathlib import Path
from dateutil.relativedelta import relativedelta

APP_ID = os.environ.get("RAKUTEN_APP_ID", "")
if not APP_ID:
    raise ValueError("âŒ RAKUTEN_APP_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚GitHub Secrets ã«ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")

# â˜… è‡ªç¤¾ã®æ¥½å¤©æ–½è¨­ç•ªå·ã¯ Secrets å¿…é ˆï¼ˆç›´æ›¸ãã—ãªã„ï¼‰
MY_HOTEL_NO = os.environ.get("RAKUTEN_MY_HOTEL_NO", "")
if not MY_HOTEL_NO or not MY_HOTEL_NO.strip().isdigit():
    raise ValueError("âŒ RAKUTEN_MY_HOTEL_NO ãŒæœªè¨­å®š or ä¸æ­£ã§ã™ã€‚GitHub Secrets ã«æ•°å­—ã®ã¿ã§ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
MY_HOTEL_NO = MY_HOTEL_NO.strip()


CACHE_FILE          = "vacancy_price_cache.json"
PREV_CACHE_FILE     = "vacancy_price_cache_previous.json"
HISTORICAL_FILE     = "historical_data.json"
SPIKE_HISTORY_FILE  = "demand_spike_history.json"
LAST_UPDATED_FILE   = "last_updated.json"   # ãƒ•ãƒ­ãƒ³ãƒˆãŒèª­ã‚€æœ€çµ‚æ›´æ–°ãƒ¡ã‚¿

RAKUTEN_VACANT_URL = "https://app.rakuten.co.jp/services/api/Travel/VacantHotelSearch/20170426"

# ------------------------------------------------------------
# å…±é€šï¼šæœ€å®‰æ–™é‡‘ã®æŠ½å‡ºï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹å·®ç•°ã«å¸åçš„ã«å¯¾å¿œï¼‰
# ------------------------------------------------------------
def _extract_min_price(resp_json) -> float | None:
    prices = []
    hotels = resp_json.get("hotels") or []
    for h in hotels:
        arr = h.get("hotel") or []
        # hotel[0] = hotelBasicInfo, hotel[1] = roomInfoç¾¤ï¼ˆã“ã¨ãŒå¤šã„ï¼‰
        # 1) roomInfoé…ä¸‹ã® dailyCharge.total
        if len(arr) >= 2 and isinstance(arr[1], dict):
            for plan in arr[1].get("roomInfo", []) or []:
                if isinstance(plan, dict):
                    dc = plan.get("dailyCharge")
                    if isinstance(dc, dict):
                        total = dc.get("total")
                        if isinstance(total, (int, float)):
                            prices.append(float(total))
        # 2) basicå´ã« roomCharge ãŒã¶ã‚‰ä¸‹ãŒã‚‹ã‚±ãƒ¼ã‚¹
        if len(arr) >= 1 and isinstance(arr[0], dict):
            basic = arr[0].get("hotelBasicInfo") or {}
            rc = basic.get("roomCharge")
            if isinstance(rc, (int, float)):
                prices.append(float(rc))
    return min(prices) if prices else None

# ------------------------------------------------------------
# æ¥½å¤©API å–å¾—ï¼ˆå¸‚å ´å´ï¼‰
# ------------------------------------------------------------
def fetch_vacancy_and_price(date: dt.date) -> dict:
    print(f"ğŸ” fetching market {date}", file=sys.stderr)
    prices = []
    vacancy_total = 0

    for page in range(1, 4):
        params = {
            "applicationId": APP_ID,
            "format": "json",
            "checkinDate":  date.strftime("%Y-%m-%d"),
            "checkoutDate": (date + dt.timedelta(days=1)).strftime("%Y-%m-%d"),
            "adultNum": 1,
            "largeClassCode":  "japan",
            "middleClassCode": "osaka",
            "smallClassCode":  "shi",
            "detailClassCode": "D",
            "page": page,
        }
        try:
            r = requests.get(RAKUTEN_VACANT_URL, params=params, timeout=10)
            r.raise_for_status()
            data = r.json()
        except Exception as e:
            print(f"  âš ï¸ fetch error on {date} page {page}: {e}", file=sys.stderr)
            continue

        if page == 1:
            vacancy_total = data.get("pagingInfo", {}).get("recordCount", 0)

        m = _extract_min_price(data)
        if isinstance(m, (int, float)):
            prices.append(float(m))

    avg_price = round(sum(prices) / len(prices), 0) if prices else 0.0
    print(f"   â†’ avg_price = {avg_price}  (vacancy={vacancy_total})", file=sys.stderr)
    return {"vacancy": vacancy_total, "avg_price": avg_price}

# ------------------------------------------------------------
# æ¥½å¤©API å–å¾—ï¼ˆè‡ªç¤¾ï¼šhotelNo æŒ‡å®šï¼‰
# ------------------------------------------------------------
def fetch_my_min_price(date: dt.date) -> float:
    """è‡ªç¤¾ï¼ˆhotelNoæŒ‡å®šï¼‰ã®å½“æ—¥æœ€å®‰æ–™é‡‘ã€‚å–å¾—ä¸å¯ã¯ 0.0 ã‚’è¿”ã™ã€‚"""
    if not MY_HOTEL_NO.isdigit():
        return 0.0
    params = {
        "applicationId": APP_ID,
        "format": "json",
        "checkinDate":  date.strftime("%Y-%m-%d"),
        "checkoutDate": (date + dt.timedelta(days=1)).strftime("%Y-%m-%d"),
        "adultNum": 1,
        "hotelNo": MY_HOTEL_NO,
        "page": 1,
    }
    try:
        r = requests.get(RAKUTEN_VACANT_URL, params=params, timeout=10)
        r.raise_for_status()
        data = r.json()
        mp = _extract_min_price(data)
        return float(mp) if isinstance(mp, (int, float)) else 0.0
    except Exception as e:
        print(f"  âš ï¸ fetch my_price error on {date}: {e}", file=sys.stderr)
        return 0.0

# ------------------------------------------------------------
# å½“æ—¥ä»¥é™ã®æœªæ¥æ—¥ã‚’æ›´æ–°
# ------------------------------------------------------------
def update_cache(start_date: dt.date, months: int = 9) -> dict:
    today             = dt.date.today()
    three_months_ago  = today - relativedelta(months=3)
    cal               = calendar.Calendar(firstweekday=calendar.SUNDAY)

    cache = {}
    if Path(CACHE_FILE).exists():
        cache = json.loads(Path(CACHE_FILE).read_text(encoding="utf-8"))

    old_cache = {}
    if Path(PREV_CACHE_FILE).exists():
        old_cache = json.loads(Path(PREV_CACHE_FILE).read_text(encoding="utf-8"))

    # éå»3ã‹æœˆã‚ˆã‚Šå‰ã¯å‰Šé™¤
    cache = {k: v for k, v in cache.items() if dt.date.fromisoformat(k) >= three_months_ago}

    for m in range(months):
        month_start = (start_date + relativedelta(months=m)).replace(day=1)
        for week in cal.monthdatescalendar(month_start.year, month_start.month):
            for day in week:
                # ç¾åœ¨ä»¥é™ã®æœªæ¥æ—¥ã ã‘å–å¾—
                if day.month != month_start.month or day <= today:
                    continue

                iso      = day.isoformat()
                market   = fetch_vacancy_and_price(day)
                # APIå¤±æ•—æ—¥ã¯ã‚¹ã‚­ãƒƒãƒ—ã—æ—¢å­˜å€¤ä¿æŒï¼ˆ0/0ã¯æ›´æ–°ã—ãªã„ï¼‰
                if market["vacancy"] == 0 and market["avg_price"] == 0.0:
                    print(f"â© skip {iso} (empty)", file=sys.stderr)
                    continue

                # â˜… è‡ªç¤¾æœ€å®‰ä¾¡æ ¼ã®å–å¾—ï¼ˆå¤±æ•—æ™‚ã¯0.0ï¼‰
                my_price = fetch_my_min_price(day)

                prev          = old_cache.get(iso, {})
                last_vac      = prev.get("vacancy",        market["vacancy"])
                last_price    = prev.get("avg_price",      market["avg_price"])
                vac_diff      = market["vacancy"] - last_vac
                price_diff    = market["avg_price"] - last_price

                # â˜… ä¹–é›¢ç‡ï¼ˆå¸‚å ´å¹³å‡æ¯”ï¼‰ã€‚ä¸¡æ–¹>0ã®ã¨ãã®ã¿è¨ˆç®—
                my_vs_avg_pct = 0.0
                if market["avg_price"] > 0 and my_price > 0:
                    my_vs_avg_pct = round((my_price - market["avg_price"]) / market["avg_price"] * 100.0, 1)

                cache[iso] = {
                    "vacancy":        market["vacancy"],
                    "avg_price":      market["avg_price"],
                    "last_vacancy":   last_vac,
                    "last_avg_price": last_price,
                    "vacancy_diff":   vac_diff,
                    "avg_price_diff": price_diff,
                    # â˜… è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã®æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ã§ä½¿ç”¨ï¼‰
                    "my_price":       my_price,
                    "my_vs_avg_pct":  my_vs_avg_pct,
                }

    Path(CACHE_FILE).write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding="utf-8")
    Path(PREV_CACHE_FILE).write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding="utf-8")
    print("âœ… cache updated", file=sys.stderr)
    return cache

def _is_date_string(s: str) -> bool:
    try:
        dt.date.fromisoformat(s)
        return True
    except ValueError:
        return False

# ------------------------------------------------------------
# éå»3ã‹æœˆã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå±¥æ­´ï¼ˆâ€»å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿æŒï¼‰
# ------------------------------------------------------------
def update_history(cache: dict):
    today       = dt.date.today()
    today_str   = today.isoformat()
    hist_data = {}

    if Path(HISTORICAL_FILE).exists():
        try:
            with open(HISTORICAL_FILE, encoding="utf-8") as f:
                hist_data = json.load(f)
        except Exception as e:
            print(f"âš ï¸ error loading historical_data.json: {e}", file=sys.stderr)

    # æœªæ¥æ—¥ã®ä»Šæ—¥æ™‚ç‚¹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¿½è¨˜ï¼ˆmy_priceã¯å±¥æ­´å¯¾è±¡å¤–ï¼‰
    for iso, v in cache.items():
        if dt.date.fromisoformat(iso) >= today:
            hist_data.setdefault(iso, {})
            hist_data[iso][today_str] = {
                "vacancy":    v["vacancy"],
                "avg_price":  v["avg_price"],
            }

    # å„å¯¾è±¡æ—¥ã®å±¥æ­´ã‚’3ã‹æœˆã«åœ§ç¸®
    for date_key in list(hist_data.keys()):
        if not _is_date_string(date_key):
            print(f"âš ï¸ skip legacy key {date_key}", file=sys.stderr)
            continue

        date_dt = dt.date.fromisoformat(date_key)
        limit   = date_dt - relativedelta(months=3)

        for hist_key in list(hist_data[date_key].keys()):
            if not _is_date_string(hist_key):
                print(f"âš ï¸ skip legacy hist_key {hist_key}", file=sys.stderr)
                del hist_data[date_key][hist_key]
                continue

            hist_dt = dt.date.fromisoformat(hist_key)
            if hist_dt < limit:
                del hist_data[date_key][hist_key]

        if not hist_data[date_key]:
            del hist_data[date_key]

    Path(HISTORICAL_FILE).write_text(json.dumps(hist_data, ensure_ascii=False, indent=2), encoding="utf-8")
    print("ğŸ“ historical_data.json updated", file=sys.stderr)

# ------------------------------------------------------------
# æ€¥é¨°æ¤œçŸ¥ï¼ˆæ–¹å‘å›ºå®šï¼šå®¢å®¤â†“ Ã— å˜ä¾¡â†‘ï¼‰
# ------------------------------------------------------------
def detect_demand_spikes(cache_data, n_recent=3, price_up_pct=0.05, vac_down_pct=0.05):
    """
    ä»•æ§˜ï¼š
      - å¯¾è±¡ã¯â€œä»Šæ—¥ä»¥é™ã®å®¿æ³Šæ—¥â€ã®ã¿
      - æ–¹å‘å›ºå®šï¼šã€å®¢å®¤ãŒ -vac_down_pct ä»¥ä¸‹ï¼ˆ= æ¸›å°‘ï¼‰ã€ã‹ã¤
                  ã€å¹³å‡å˜ä¾¡ãŒ +price_up_pct ä»¥ä¸Šï¼ˆ= ä¸Šæ˜‡ï¼‰ã€ã®æ™‚ã ã‘æ¤œçŸ¥
      - å‰å›å€¤(last_*)ãŒç„¡ã„/0 ã®é …ç›®ã¯è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—
      - è¿‘ã„å®¿æ³Šæ—¥ã®é™¤å¤–ã¯ãƒ•ãƒ­ãƒ³ãƒˆ(app.js)å´ã§å®Ÿæ–½æ¸ˆã¿
    """
    sorted_dates = sorted(cache_data.keys())
    today = dt.date.today()

    results = []
    for d in sorted_dates:
        # å®¿æ³Šæ—¥ãŒéå»ãªã‚‰é™¤å¤–
        try:
            stay_dt = dt.date.fromisoformat(d)
        except Exception:
            continue
        if stay_dt < today:
            continue

        rec = cache_data[d]
        last_price = rec.get("last_avg_price", 0)
        last_vac   = rec.get("last_vacancy", 0)
        cur_price  = rec.get("avg_price", 0)
        cur_vac    = rec.get("vacancy", 0)

        # å‰å›å€¤ãŒæ¬ æ or 0 ã¯åˆ¤å®šä¸å¯
        if not (last_price and last_vac):
            continue

        # å·®åˆ†ï¼ˆç¬¦å·ä»˜ãï¼‰ã¨æ¯”ç‡ï¼ˆç¬¦å·ä»˜ãï¼‰
        price_diff = cur_price - last_price      # + ãªã‚‰å˜ä¾¡â†‘
        vac_diff   = cur_vac   - last_vac        # - ãªã‚‰å®¢å®¤â†“
        price_ratio = (price_diff / last_price) if last_price else 0.0
        vac_ratio   = (vac_diff   / last_vac)   if last_vac   else 0.0

        # æ–¹å‘ï¼†é–¾å€¤ï¼šå®¢å®¤â†“ AND å˜ä¾¡â†‘
        if (vac_ratio <= -vac_down_pct) and (price_ratio >= price_up_pct):
            results.append({
                "spike_date": d,
                "price": cur_price,
                "last_price": last_price,
                "price_diff": price_diff,
                "price_ratio": round(float(price_ratio), 4),
                "vacancy": cur_vac,
                "last_vac": last_vac,
                "vacancy_diff": vac_diff,
                "vacancy_ratio": round(float(vac_ratio), 4),
            })

    print(f"ğŸ“Š Demand Spikes Detected (dir-fixed: priceâ†‘ & vacâ†“): {len(results)} ä»¶", file=sys.stderr)
    return results

# ------------------------------------------------------------
# å±¥æ­´ã®ä¿å­˜ï¼ˆéå»å®¿æ³Šæ—¥ãƒ»æ–¹å‘é€†ã‚’ä¸€æ‹¬ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼‰
# ------------------------------------------------------------
def save_demand_spike_history(demand_spikes, history_file=SPIKE_HISTORY_FILE):
    """å±¥æ­´ã‚’æ›´æ–°ã—ã¤ã¤ã€
       1) 90æ—¥ã‚ˆã‚Šå‰ã®ã‚­ãƒ¼ã‚’å‰Šé™¤
       2) å…¨ã‚­ãƒ¼æ¨ªæ–­ã§ã€éå»æ—¥ã®spikeã€ã‚’å‰Šé™¤
       3) æ–¹å‘ãŒé€†ï¼ˆå˜ä¾¡â†“ or å®¢å®¤â†‘ï¼‰ã®spikeã‚’å‰Šé™¤
    """
    today_dt = dt.date.today()
    today_iso = today_dt.isoformat()

    # æ—¢å­˜å±¥æ­´ãƒ­ãƒ¼ãƒ‰
    if os.path.exists(history_file):
        try:
            with open(history_file, "r", encoding="utf-8") as f:
                history = json.load(f)
        except Exception as e:
            print(f"âš ï¸ error loading {history_file}: {e}", file=sys.stderr)
            history = {}
    else:
        history = {}

    # ä»Šæ—¥åˆ†ã‚’å·®ã—æ›¿ãˆ
    history[today_iso] = demand_spikes or []

    # 90æ—¥ã‚ˆã‚Šå‰ã®ã‚­ãƒ¼ã‚’å‰Šé™¤
    limit = (today_dt - dt.timedelta(days=90)).isoformat()
    history = {d: v for d, v in history.items() if d >= limit}

    # å…¨ã‚­ãƒ¼ã«å¯¾ã—ã¦ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼š
    #  1) spike_date ãŒéå»æ—¥ã®ã‚‚ã®ã¯é™¤å¤–
    #  2) æ–¹å‘ãƒã‚§ãƒƒã‚¯ï¼š price_diff > 0ï¼ˆå˜ä¾¡â†‘ï¼‰ã‹ã¤ vacancy_diff < 0ï¼ˆå®¢å®¤â†“ï¼‰ã®ã¿æ®‹ã™
    cleaned = {}
    for up_date, items in history.items():
        new_items = []
        for it in items or []:
            sd = it.get("spike_date")
            try:
                if sd and dt.date.fromisoformat(sd) < today_dt:
                    continue  # éå»å®¿æ³Šæ—¥ã®ã‚¹ãƒ‘ã‚¤ã‚¯ã¯æ¨ã¦ã‚‹
            except Exception:
                pass

            p_diff = it.get("price_diff", 0)
            v_diff = it.get("vacancy_diff", 0)
            if not (isinstance(p_diff, (int, float)) and isinstance(v_diff, (int, float))):
                continue
            if not (p_diff > 0 and v_diff < 0):
                continue  # æ–¹å‘ãŒé€†ã¯æ¨ã¦ã‚‹

            new_items.append(it)
        cleaned[up_date] = new_items

    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(cleaned, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“ {history_file} cleaned & updated", file=sys.stderr)

# ------------------------------------------------------------
# æœ€çµ‚æ›´æ–°ãƒ¡ã‚¿ã®æ›¸ãå‡ºã—ï¼ˆJSTï¼‰
# ------------------------------------------------------------
def write_last_updated():
    """Actions å®Ÿè¡Œå®Œäº†æ™‚ç‚¹ã®JSTæ™‚åˆ»ãªã©ã‚’ last_updated.json ã«ä¿å­˜"""
    JST = dt.timezone(dt.timedelta(hours=9))
    now = dt.datetime.now(JST)
    payload = {
        "last_updated_iso": now.isoformat(timespec="seconds"),
        "last_updated_jst": now.strftime("%Y-%m-%d %H:%M:%S JST"),
        "source": "github-actions",
        "git_sha": os.environ.get("GITHUB_SHA", "")[:7],
        "note": "vacancy/price crawl finished",
    }
    try:
        with open(LAST_UPDATED_FILE, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        print(f"ğŸ•’ {LAST_UPDATED_FILE} written: {payload['last_updated_jst']}", file=sys.stderr)
    except Exception as e:
        print(f"âš ï¸ failed to write {LAST_UPDATED_FILE}: {e}", file=sys.stderr)

# ------------------------------------------------------------
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# ------------------------------------------------------------
if __name__ == "__main__":
    print("ğŸ“¡ update_cache.py start", file=sys.stderr)

    cache_now = update_cache(start_date=dt.date.today(), months=9)
    update_history(cache_now)

    demand_spikes = detect_demand_spikes(
        cache_data=cache_now,
        n_recent=3,
        price_up_pct=0.05,   # å˜ä¾¡â†‘5%ä»¥ä¸Š
        vac_down_pct=0.05    # å®¢å®¤â†“5%ä»¥ä¸Š
    )
    print(f"Demand spikes for today: {demand_spikes}", file=sys.stderr)
    save_demand_spike_history(demand_spikes)

    # ã™ã¹ã¦ã®æ›´æ–°ãŒå®Œäº†ã—ãŸâ€œæœ€å¾Œâ€ã«æ›¸ãå‡ºã—
    write_last_updated()
    print("âœ¨ all done", file=sys.stderr)
